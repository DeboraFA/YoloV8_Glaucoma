{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d0281b",
   "metadata": {},
   "source": [
    "# Train YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d299a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "\n",
    "results = model.train(\n",
    "        batch=8,\n",
    "#         device=\"cpu\",\n",
    "        data=\"data_refuge2.yaml\",\n",
    "        epochs=1,\n",
    "        imgsz=640,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3154d90",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as show_image\n",
    "show_image(filename=\"runs/segment/train_yolo/val_batch0_pred.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a77a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "yolo_model = YOLO( './runs/segment/train3/weights/best.pt' ) \n",
    "yolo_model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "\n",
    "path = 'C:/Users/debora.assis/Documents/REFUGE/test/images'\n",
    "\n",
    "for image_path in glob.glob(path + \"/*\"):\n",
    "    results = list (yolo_model(image_path, conf= 0.1)) \n",
    "    result = results[0]\n",
    "    \n",
    "    \n",
    "    if len(result) == 1:\n",
    "        mask_result = T.ToPILImage()(result.masks.masks)\n",
    "     \n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_name = image_path.split('\\\\')[1][:-4]\n",
    "        \n",
    "        contours_cup = cv2.findContours(np.array(mask_result), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_cup = imutils.grab_contours(contours_cup)\n",
    "\n",
    "        result  = img.copy()\n",
    "        result = cv2.resize(img, (224,224))\n",
    "        for cnt_cup in contours_cup:\n",
    "            cv2.drawContours(result, [cnt_cup], -1, (0, 255, 0), thickness=1)\n",
    "\n",
    "                \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 8))\n",
    "\n",
    "        ax = ax.flatten()\n",
    "        for a in ax:\n",
    "            ax[0].imshow(img)\n",
    "            ax[0].set_title(str(img_name), fontsize=12)\n",
    "            ax[0].set_xticks([])\n",
    "            ax[0].set_yticks([])\n",
    "\n",
    "            ax[1].imshow(mask_result)\n",
    "            ax[1].set_title('Predic Mask', fontsize=12)\n",
    "            ax[1].set_xticks([])\n",
    "            ax[1].set_yticks([])\n",
    "\n",
    "            ax[2].imshow(result)\n",
    "            ax[2].set_title('Contour image', fontsize=12)\n",
    "            ax[2].set_xticks([])\n",
    "            ax[2].set_yticks([])\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e9c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
